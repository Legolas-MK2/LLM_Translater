{
  "best_metric": 1.6297297477722168,
  "best_model_checkpoint": "checkpoints/20241118_073529/checkpoints/checkpoint-5000",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 5030,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.019880715705765408,
      "grad_norm": 0.0006319083622656763,
      "learning_rate": 9.92063492063492e-05,
      "loss": 0.0029,
      "step": 50
    },
    {
      "epoch": 0.039761431411530816,
      "grad_norm": 0.00047174427891150117,
      "learning_rate": 0.0001984126984126984,
      "loss": 0.0024,
      "step": 100
    },
    {
      "epoch": 0.05964214711729622,
      "grad_norm": 0.00028181105153635144,
      "learning_rate": 0.00029761904761904765,
      "loss": 0.0018,
      "step": 150
    },
    {
      "epoch": 0.07952286282306163,
      "grad_norm": 0.00024965303600765765,
      "learning_rate": 0.0003968253968253968,
      "loss": 0.0017,
      "step": 200
    },
    {
      "epoch": 0.09940357852882704,
      "grad_norm": 0.0003106710792053491,
      "learning_rate": 0.000496031746031746,
      "loss": 0.0016,
      "step": 250
    },
    {
      "epoch": 0.11928429423459244,
      "grad_norm": 0.00031045672949403524,
      "learning_rate": 0.0004949769778149854,
      "loss": 0.0016,
      "step": 300
    },
    {
      "epoch": 0.13916500994035785,
      "grad_norm": 0.00028255858342163265,
      "learning_rate": 0.0004897446630389284,
      "loss": 0.0016,
      "step": 350
    },
    {
      "epoch": 0.15904572564612326,
      "grad_norm": 0.0002922959974966943,
      "learning_rate": 0.0004845123482628715,
      "loss": 0.0016,
      "step": 400
    },
    {
      "epoch": 0.17892644135188868,
      "grad_norm": 0.00033988209906965494,
      "learning_rate": 0.0004792800334868146,
      "loss": 0.0015,
      "step": 450
    },
    {
      "epoch": 0.1988071570576541,
      "grad_norm": 0.0003185044042766094,
      "learning_rate": 0.00047404771871075764,
      "loss": 0.0015,
      "step": 500
    },
    {
      "epoch": 0.1988071570576541,
      "eval_loss": 2.246502637863159,
      "eval_runtime": 162.9839,
      "eval_samples_per_second": 20.579,
      "eval_steps_per_second": 5.148,
      "step": 500
    },
    {
      "epoch": 0.21868787276341947,
      "grad_norm": 0.0003688439028337598,
      "learning_rate": 0.0004688154039347007,
      "loss": 0.0015,
      "step": 550
    },
    {
      "epoch": 0.23856858846918488,
      "grad_norm": 0.00035282803582958877,
      "learning_rate": 0.0004635830891586438,
      "loss": 0.0014,
      "step": 600
    },
    {
      "epoch": 0.2584493041749503,
      "grad_norm": 0.0004316071863286197,
      "learning_rate": 0.00045835077438258686,
      "loss": 0.0014,
      "step": 650
    },
    {
      "epoch": 0.2783300198807157,
      "grad_norm": 0.0004470282874535769,
      "learning_rate": 0.00045311845960652994,
      "loss": 0.0014,
      "step": 700
    },
    {
      "epoch": 0.2982107355864811,
      "grad_norm": 0.0004926421097479761,
      "learning_rate": 0.000447886144830473,
      "loss": 0.0013,
      "step": 750
    },
    {
      "epoch": 0.31809145129224653,
      "grad_norm": 0.0005365688703022897,
      "learning_rate": 0.0004426538300544161,
      "loss": 0.0014,
      "step": 800
    },
    {
      "epoch": 0.3379721669980119,
      "grad_norm": 0.00038556166691705585,
      "learning_rate": 0.00043742151527835916,
      "loss": 0.0013,
      "step": 850
    },
    {
      "epoch": 0.35785288270377735,
      "grad_norm": 0.00043627413106150925,
      "learning_rate": 0.0004321892005023022,
      "loss": 0.0013,
      "step": 900
    },
    {
      "epoch": 0.37773359840954274,
      "grad_norm": 0.0003335355722811073,
      "learning_rate": 0.0004269568857262453,
      "loss": 0.0013,
      "step": 950
    },
    {
      "epoch": 0.3976143141153082,
      "grad_norm": 0.00034835879341699183,
      "learning_rate": 0.00042172457095018834,
      "loss": 0.0013,
      "step": 1000
    },
    {
      "epoch": 0.3976143141153082,
      "eval_loss": 1.9727871417999268,
      "eval_runtime": 162.8364,
      "eval_samples_per_second": 20.597,
      "eval_steps_per_second": 5.152,
      "step": 1000
    },
    {
      "epoch": 0.41749502982107356,
      "grad_norm": 0.0004565370618365705,
      "learning_rate": 0.00041649225617413146,
      "loss": 0.0013,
      "step": 1050
    },
    {
      "epoch": 0.43737574552683894,
      "grad_norm": 0.0003908457583747804,
      "learning_rate": 0.00041125994139807454,
      "loss": 0.0013,
      "step": 1100
    },
    {
      "epoch": 0.4572564612326044,
      "grad_norm": 0.0005526277818717062,
      "learning_rate": 0.00040602762662201756,
      "loss": 0.0013,
      "step": 1150
    },
    {
      "epoch": 0.47713717693836977,
      "grad_norm": 0.000453027751063928,
      "learning_rate": 0.0004007953118459607,
      "loss": 0.0013,
      "step": 1200
    },
    {
      "epoch": 0.4970178926441352,
      "grad_norm": 0.0004354342236183584,
      "learning_rate": 0.0003955629970699037,
      "loss": 0.0013,
      "step": 1250
    },
    {
      "epoch": 0.5168986083499006,
      "grad_norm": 0.0003644447133410722,
      "learning_rate": 0.00039033068229384684,
      "loss": 0.0012,
      "step": 1300
    },
    {
      "epoch": 0.536779324055666,
      "grad_norm": 0.00044644036097452044,
      "learning_rate": 0.00038509836751778986,
      "loss": 0.0012,
      "step": 1350
    },
    {
      "epoch": 0.5566600397614314,
      "grad_norm": 0.00041773650445975363,
      "learning_rate": 0.000379866052741733,
      "loss": 0.0012,
      "step": 1400
    },
    {
      "epoch": 0.5765407554671969,
      "grad_norm": 0.00035917095374315977,
      "learning_rate": 0.000374633737965676,
      "loss": 0.0012,
      "step": 1450
    },
    {
      "epoch": 0.5964214711729622,
      "grad_norm": 0.00040007472853176296,
      "learning_rate": 0.0003694014231896191,
      "loss": 0.0012,
      "step": 1500
    },
    {
      "epoch": 0.5964214711729622,
      "eval_loss": 1.8452556133270264,
      "eval_runtime": 162.9327,
      "eval_samples_per_second": 20.585,
      "eval_steps_per_second": 5.149,
      "step": 1500
    },
    {
      "epoch": 0.6163021868787276,
      "grad_norm": 0.0003208941197954118,
      "learning_rate": 0.00036416910841356216,
      "loss": 0.0012,
      "step": 1550
    },
    {
      "epoch": 0.6361829025844931,
      "grad_norm": 0.0003749649040400982,
      "learning_rate": 0.00035893679363750524,
      "loss": 0.0012,
      "step": 1600
    },
    {
      "epoch": 0.6560636182902585,
      "grad_norm": 0.00038291100645437837,
      "learning_rate": 0.0003537044788614483,
      "loss": 0.0012,
      "step": 1650
    },
    {
      "epoch": 0.6759443339960238,
      "grad_norm": 0.00046038482105359435,
      "learning_rate": 0.0003484721640853914,
      "loss": 0.0012,
      "step": 1700
    },
    {
      "epoch": 0.6958250497017893,
      "grad_norm": 0.0003763439308386296,
      "learning_rate": 0.00034323984930933446,
      "loss": 0.0012,
      "step": 1750
    },
    {
      "epoch": 0.7157057654075547,
      "grad_norm": 0.0005374207394197583,
      "learning_rate": 0.00033800753453327754,
      "loss": 0.0012,
      "step": 1800
    },
    {
      "epoch": 0.73558648111332,
      "grad_norm": 0.0004310564836487174,
      "learning_rate": 0.00033277521975722056,
      "loss": 0.0011,
      "step": 1850
    },
    {
      "epoch": 0.7554671968190855,
      "grad_norm": 0.0004001141933258623,
      "learning_rate": 0.0003275429049811637,
      "loss": 0.0012,
      "step": 1900
    },
    {
      "epoch": 0.7753479125248509,
      "grad_norm": 0.0004338659346103668,
      "learning_rate": 0.0003223105902051067,
      "loss": 0.0012,
      "step": 1950
    },
    {
      "epoch": 0.7952286282306164,
      "grad_norm": 0.00038943724939599633,
      "learning_rate": 0.00031707827542904984,
      "loss": 0.0011,
      "step": 2000
    },
    {
      "epoch": 0.7952286282306164,
      "eval_loss": 1.770712971687317,
      "eval_runtime": 163.0143,
      "eval_samples_per_second": 20.575,
      "eval_steps_per_second": 5.147,
      "step": 2000
    },
    {
      "epoch": 0.8151093439363817,
      "grad_norm": 0.0003257296048104763,
      "learning_rate": 0.00031184596065299286,
      "loss": 0.0011,
      "step": 2050
    },
    {
      "epoch": 0.8349900596421471,
      "grad_norm": 0.00034030326060019433,
      "learning_rate": 0.000306613645876936,
      "loss": 0.0011,
      "step": 2100
    },
    {
      "epoch": 0.8548707753479126,
      "grad_norm": 0.0003391780483070761,
      "learning_rate": 0.000301381331100879,
      "loss": 0.0012,
      "step": 2150
    },
    {
      "epoch": 0.8747514910536779,
      "grad_norm": 0.00041569944005459547,
      "learning_rate": 0.0002961490163248221,
      "loss": 0.0011,
      "step": 2200
    },
    {
      "epoch": 0.8946322067594433,
      "grad_norm": 0.0004269927740097046,
      "learning_rate": 0.0002909167015487652,
      "loss": 0.0011,
      "step": 2250
    },
    {
      "epoch": 0.9145129224652088,
      "grad_norm": 0.00035496646887622774,
      "learning_rate": 0.00028568438677270823,
      "loss": 0.0012,
      "step": 2300
    },
    {
      "epoch": 0.9343936381709742,
      "grad_norm": 0.000423793972004205,
      "learning_rate": 0.00028045207199665136,
      "loss": 0.0011,
      "step": 2350
    },
    {
      "epoch": 0.9542743538767395,
      "grad_norm": 0.00040818919660523534,
      "learning_rate": 0.0002752197572205944,
      "loss": 0.0011,
      "step": 2400
    },
    {
      "epoch": 0.974155069582505,
      "grad_norm": 0.0004632845229934901,
      "learning_rate": 0.0002699874424445375,
      "loss": 0.0011,
      "step": 2450
    },
    {
      "epoch": 0.9940357852882704,
      "grad_norm": 0.0003621918731369078,
      "learning_rate": 0.00026475512766848053,
      "loss": 0.0011,
      "step": 2500
    },
    {
      "epoch": 0.9940357852882704,
      "eval_loss": 1.7223706245422363,
      "eval_runtime": 163.0283,
      "eval_samples_per_second": 20.573,
      "eval_steps_per_second": 5.146,
      "step": 2500
    },
    {
      "epoch": 1.0139165009940359,
      "grad_norm": 0.00039496825775131583,
      "learning_rate": 0.0002595228128924236,
      "loss": 0.0012,
      "step": 2550
    },
    {
      "epoch": 1.0337972166998013,
      "grad_norm": 0.0003653143357951194,
      "learning_rate": 0.0002542904981163667,
      "loss": 0.0011,
      "step": 2600
    },
    {
      "epoch": 1.0536779324055665,
      "grad_norm": 0.00031396449776366353,
      "learning_rate": 0.00024905818334030976,
      "loss": 0.0011,
      "step": 2650
    },
    {
      "epoch": 1.073558648111332,
      "grad_norm": 0.0004266702162567526,
      "learning_rate": 0.0002438258685642528,
      "loss": 0.0011,
      "step": 2700
    },
    {
      "epoch": 1.0934393638170974,
      "grad_norm": 0.00035636796383187175,
      "learning_rate": 0.0002385935537881959,
      "loss": 0.0011,
      "step": 2750
    },
    {
      "epoch": 1.1133200795228628,
      "grad_norm": 0.00036912524956278503,
      "learning_rate": 0.00023336123901213898,
      "loss": 0.0011,
      "step": 2800
    },
    {
      "epoch": 1.1332007952286283,
      "grad_norm": 0.0003376129607204348,
      "learning_rate": 0.00022812892423608206,
      "loss": 0.0011,
      "step": 2850
    },
    {
      "epoch": 1.1530815109343937,
      "grad_norm": 0.000411037151934579,
      "learning_rate": 0.00022289660946002513,
      "loss": 0.0011,
      "step": 2900
    },
    {
      "epoch": 1.1729622266401591,
      "grad_norm": 0.00045323173981159925,
      "learning_rate": 0.0002176642946839682,
      "loss": 0.0011,
      "step": 2950
    },
    {
      "epoch": 1.1928429423459244,
      "grad_norm": 0.0003890929219778627,
      "learning_rate": 0.00021243197990791128,
      "loss": 0.0011,
      "step": 3000
    },
    {
      "epoch": 1.1928429423459244,
      "eval_loss": 1.6897857189178467,
      "eval_runtime": 163.1877,
      "eval_samples_per_second": 20.553,
      "eval_steps_per_second": 5.141,
      "step": 3000
    },
    {
      "epoch": 1.2127236580516898,
      "grad_norm": 0.00038476218469440937,
      "learning_rate": 0.00020719966513185433,
      "loss": 0.0011,
      "step": 3050
    },
    {
      "epoch": 1.2326043737574552,
      "grad_norm": 0.0004653958894778043,
      "learning_rate": 0.0002019673503557974,
      "loss": 0.0011,
      "step": 3100
    },
    {
      "epoch": 1.2524850894632207,
      "grad_norm": 0.0004103778628632426,
      "learning_rate": 0.00019673503557974048,
      "loss": 0.0011,
      "step": 3150
    },
    {
      "epoch": 1.2723658051689861,
      "grad_norm": 0.0004445059166755527,
      "learning_rate": 0.00019150272080368356,
      "loss": 0.001,
      "step": 3200
    },
    {
      "epoch": 1.2922465208747516,
      "grad_norm": 0.0006016409024596214,
      "learning_rate": 0.00018627040602762663,
      "loss": 0.0011,
      "step": 3250
    },
    {
      "epoch": 1.3121272365805168,
      "grad_norm": 0.0003724481211975217,
      "learning_rate": 0.0001810380912515697,
      "loss": 0.0011,
      "step": 3300
    },
    {
      "epoch": 1.3320079522862822,
      "grad_norm": 0.00037838623393327,
      "learning_rate": 0.00017580577647551278,
      "loss": 0.0011,
      "step": 3350
    },
    {
      "epoch": 1.3518886679920477,
      "grad_norm": 0.0003584426885936409,
      "learning_rate": 0.00017057346169945583,
      "loss": 0.0011,
      "step": 3400
    },
    {
      "epoch": 1.371769383697813,
      "grad_norm": 0.00037469013477675617,
      "learning_rate": 0.0001653411469233989,
      "loss": 0.0011,
      "step": 3450
    },
    {
      "epoch": 1.3916500994035785,
      "grad_norm": 0.0005294848815537989,
      "learning_rate": 0.00016010883214734198,
      "loss": 0.0011,
      "step": 3500
    },
    {
      "epoch": 1.3916500994035785,
      "eval_loss": 1.6650718450546265,
      "eval_runtime": 163.4596,
      "eval_samples_per_second": 20.519,
      "eval_steps_per_second": 5.133,
      "step": 3500
    },
    {
      "epoch": 1.411530815109344,
      "grad_norm": 0.0004105233820155263,
      "learning_rate": 0.00015487651737128505,
      "loss": 0.0011,
      "step": 3550
    },
    {
      "epoch": 1.4314115308151094,
      "grad_norm": 0.00038971705362200737,
      "learning_rate": 0.00014964420259522813,
      "loss": 0.0011,
      "step": 3600
    },
    {
      "epoch": 1.4512922465208749,
      "grad_norm": 0.00034932870767079294,
      "learning_rate": 0.0001444118878191712,
      "loss": 0.0011,
      "step": 3650
    },
    {
      "epoch": 1.4711729622266403,
      "grad_norm": 0.00047589096357114613,
      "learning_rate": 0.00013917957304311425,
      "loss": 0.0011,
      "step": 3700
    },
    {
      "epoch": 1.4910536779324055,
      "grad_norm": 0.0005659923772327602,
      "learning_rate": 0.00013394725826705733,
      "loss": 0.0011,
      "step": 3750
    },
    {
      "epoch": 1.510934393638171,
      "grad_norm": 0.0004745143814943731,
      "learning_rate": 0.0001287149434910004,
      "loss": 0.0011,
      "step": 3800
    },
    {
      "epoch": 1.5308151093439364,
      "grad_norm": 0.0004916097968816757,
      "learning_rate": 0.0001234826287149435,
      "loss": 0.0011,
      "step": 3850
    },
    {
      "epoch": 1.5506958250497018,
      "grad_norm": 0.0004068737616762519,
      "learning_rate": 0.00011825031393888657,
      "loss": 0.0011,
      "step": 3900
    },
    {
      "epoch": 1.570576540755467,
      "grad_norm": 0.0004011056153103709,
      "learning_rate": 0.00011301799916282964,
      "loss": 0.0011,
      "step": 3950
    },
    {
      "epoch": 1.5904572564612325,
      "grad_norm": 0.0004061032959725708,
      "learning_rate": 0.0001077856843867727,
      "loss": 0.0011,
      "step": 4000
    },
    {
      "epoch": 1.5904572564612325,
      "eval_loss": 1.646558403968811,
      "eval_runtime": 163.2438,
      "eval_samples_per_second": 20.546,
      "eval_steps_per_second": 5.14,
      "step": 4000
    },
    {
      "epoch": 1.610337972166998,
      "grad_norm": 0.0003541741461958736,
      "learning_rate": 0.00010255336961071578,
      "loss": 0.0011,
      "step": 4050
    },
    {
      "epoch": 1.6302186878727634,
      "grad_norm": 0.0006162635399959981,
      "learning_rate": 9.732105483465887e-05,
      "loss": 0.0011,
      "step": 4100
    },
    {
      "epoch": 1.6500994035785288,
      "grad_norm": 0.0003888930077664554,
      "learning_rate": 9.208874005860193e-05,
      "loss": 0.0011,
      "step": 4150
    },
    {
      "epoch": 1.6699801192842942,
      "grad_norm": 0.0007485659443773329,
      "learning_rate": 8.6856425282545e-05,
      "loss": 0.001,
      "step": 4200
    },
    {
      "epoch": 1.6898608349900597,
      "grad_norm": 0.00041430213605053723,
      "learning_rate": 8.162411050648808e-05,
      "loss": 0.0011,
      "step": 4250
    },
    {
      "epoch": 1.7097415506958251,
      "grad_norm": 0.00031493502319790423,
      "learning_rate": 7.639179573043114e-05,
      "loss": 0.0011,
      "step": 4300
    },
    {
      "epoch": 1.7296222664015906,
      "grad_norm": 0.0004030738491564989,
      "learning_rate": 7.115948095437421e-05,
      "loss": 0.001,
      "step": 4350
    },
    {
      "epoch": 1.749502982107356,
      "grad_norm": 0.00036476986133493483,
      "learning_rate": 6.592716617831729e-05,
      "loss": 0.001,
      "step": 4400
    },
    {
      "epoch": 1.7693836978131214,
      "grad_norm": 0.00033923881710506976,
      "learning_rate": 6.069485140226036e-05,
      "loss": 0.001,
      "step": 4450
    },
    {
      "epoch": 1.7892644135188867,
      "grad_norm": 0.00036155348061583936,
      "learning_rate": 5.546253662620343e-05,
      "loss": 0.001,
      "step": 4500
    },
    {
      "epoch": 1.7892644135188867,
      "eval_loss": 1.635148286819458,
      "eval_runtime": 163.2266,
      "eval_samples_per_second": 20.548,
      "eval_steps_per_second": 5.14,
      "step": 4500
    },
    {
      "epoch": 1.809145129224652,
      "grad_norm": 0.00043756701052188873,
      "learning_rate": 5.023022185014651e-05,
      "loss": 0.001,
      "step": 4550
    },
    {
      "epoch": 1.8290258449304175,
      "grad_norm": 0.00041673099622130394,
      "learning_rate": 4.4997907074089576e-05,
      "loss": 0.001,
      "step": 4600
    },
    {
      "epoch": 1.8489065606361827,
      "grad_norm": 0.0003415065002627671,
      "learning_rate": 3.976559229803265e-05,
      "loss": 0.0011,
      "step": 4650
    },
    {
      "epoch": 1.8687872763419482,
      "grad_norm": 0.000323647225741297,
      "learning_rate": 3.453327752197572e-05,
      "loss": 0.0011,
      "step": 4700
    },
    {
      "epoch": 1.8886679920477136,
      "grad_norm": 0.0004416608717292547,
      "learning_rate": 2.9300962745918795e-05,
      "loss": 0.001,
      "step": 4750
    },
    {
      "epoch": 1.908548707753479,
      "grad_norm": 0.00041622944991104305,
      "learning_rate": 2.4068647969861866e-05,
      "loss": 0.001,
      "step": 4800
    },
    {
      "epoch": 1.9284294234592445,
      "grad_norm": 0.00043054597335867584,
      "learning_rate": 1.8836333193804938e-05,
      "loss": 0.0011,
      "step": 4850
    },
    {
      "epoch": 1.94831013916501,
      "grad_norm": 0.0004573444020934403,
      "learning_rate": 1.3604018417748013e-05,
      "loss": 0.001,
      "step": 4900
    },
    {
      "epoch": 1.9681908548707754,
      "grad_norm": 0.000377201329683885,
      "learning_rate": 8.371703641691083e-06,
      "loss": 0.0011,
      "step": 4950
    },
    {
      "epoch": 1.9880715705765408,
      "grad_norm": 0.0003712625184562057,
      "learning_rate": 3.1393888656341567e-06,
      "loss": 0.001,
      "step": 5000
    },
    {
      "epoch": 1.9880715705765408,
      "eval_loss": 1.6297297477722168,
      "eval_runtime": 163.4296,
      "eval_samples_per_second": 20.523,
      "eval_steps_per_second": 5.134,
      "step": 5000
    }
  ],
  "logging_steps": 50,
  "max_steps": 5030,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.481002517869363e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
